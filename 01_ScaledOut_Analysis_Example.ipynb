{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from math import pi\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import get_client\n",
    "from dask.distributed import wait\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import ROOT \n",
    "from ROOT import TCanvas, TH1F, TLegend, TFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ip = \"128.211.148.61\"\n",
    "slurm_port = \"38220\"\n",
    "client = Client(f\"{node_ip}:{slurm_port}\")\n",
    "print(f\"Connected to cluster!\")\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(file):\n",
    "    import awkward as ak\n",
    "    import vector\n",
    "    vector.register_awkward()\n",
    "\n",
    "    tree = uproot.open(file)[\"Events\"]\n",
    "    muons = ak.Array(\n",
    "        ak.zip(\n",
    "            {\n",
    "                \"nmu\": tree[\"nMuon\"].array(),\n",
    "                \"pt\": tree[\"Muon_pt\"].array(),\n",
    "                \"eta\": tree[\"Muon_eta\"].array(),\n",
    "                \"charge\": tree[\"Muon_charge\"].array(),\n",
    "                \"id\": tree[\"Muon_isGlobal\"].array(),\n",
    "                \"phi\": tree[\"Muon_phi\"].array(),\n",
    "                \"mass\": tree[\"Muon_mass\"].array(),\n",
    "                \"met\": tree[\"MET_pt\"].array()\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    muon_mask = (muons.id==1) & (muons.pt > 20) & (abs(muons.eta)<2.4)\n",
    "    good_muons = muons[muon_mask]\n",
    "    two_muons = good_muons[(ak.sum(muon_mask, axis=-1)==2)]\n",
    "    opp_muons = two_muons.charge[:,0] != two_muons.charge[:,1]\n",
    "\n",
    "    two_opp_good_muons = two_muons[opp_muons]\n",
    "\n",
    "    mu_p4 = ak.Array(\n",
    "        ak.zip(\n",
    "            {\n",
    "                \"pt\":two_opp_good_muons.pt,\n",
    "                \"eta\":two_opp_good_muons.eta,\n",
    "                \"phi\":two_opp_good_muons.phi,\n",
    "                \"mass\":two_opp_good_muons.mass\n",
    "            }\n",
    "        ), with_name = \"Momentum4D\"\n",
    "    )\n",
    "\n",
    "    dimuon_p4 = mu_p4[:,0] + mu_p4[:,1]\n",
    "\n",
    "    mu_cols = [\"pt\", \"eta\", \"phi\"]\n",
    "    df_mu1 = ak.to_pandas(two_opp_good_muons[:,0][mu_cols])\n",
    "    df_mu1 = df_mu1.add_prefix('mu1_')\n",
    "    \n",
    "    df_mu2 = ak.to_pandas(two_opp_good_muons[:,1][mu_cols])\n",
    "    df_mu2 = df_mu2.add_prefix('mu2_')\n",
    "    \n",
    "    df_met = pd.DataFrame(two_opp_good_muons.met[:,0],columns=['MET'])\n",
    "\n",
    "    df = pd.concat([df_mu1, df_mu2, df_met], axis=1)\n",
    "    df[\"dimuon_mass\"] = dimuon_p4.M\n",
    "\n",
    "    return dd.from_pandas(df, npartitions=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "path = \"/mnt/hadoop/store/mc/RunIISummer20UL18NanoAODv2/DYJetsToLL_M-50_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/106X_upgrade2018_realistic_v15_L1v1-v1/50000/\"\n",
    "for f in glob.glob(path+\"*.root\"):\n",
    "    all_files.append(f)\n",
    "    \n",
    "all_files1 = []\n",
    "path = \"/mnt/hadoop//store/mc/RunIISummer20UL18NanoAODv2/TTTo2L2Nu_TuneCP5_13TeV-powheg-pythia8/NANOAODSIM/106X_upgrade2018_realistic_v15_L1v1-v1/270000/\"\n",
    "for f in glob.glob(path+\"*.root\"):\n",
    "    all_files1.append(f)\n",
    "    \n",
    "all_files2 = []\n",
    "path = \"/mnt/hadoop//store/data/Run2018D/DoubleMuon/NANOAOD/UL2018_MiniAODv2_NanoAODv9_GT36-v1/2820000/\"\n",
    "for f in glob.glob(path+\"*.root\"):\n",
    "    all_files2.append(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "futuresdy = client.map(processor, all_files)\n",
    "futurestt = client.map(processor, all_files1)\n",
    "futuresdd = client.map(processor, all_files2)\n",
    "\n",
    "\n",
    "#wait(futuresdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = {\n",
    "    \"dy\": futuresdy,\n",
    "    \"tt\": futurestt,\n",
    "    \"data\": futuresdd\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for key, future in futures.items():\n",
    "    results[key] = dd.concat(client.gather(future))\n",
    "    #for result in results:\n",
    "    #    mass = result.M\n",
    "    #    \n",
    "    #    total_M = dd.concat([total_M, mass])\n",
    "    #total_info[i] = total_M\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import mplhep as hep\n",
    "\n",
    "# style = hep.style.CMS\n",
    "# style[\"mathtext.fontset\"] = \"cm\"\n",
    "# style[\"mathtext.default\"] = \"rm\"\n",
    "# plt.style.use(style)\n",
    "\n",
    "'''Plot dimuon invariant mass'''\n",
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "\n",
    "for key, res in results.items():\n",
    "    mass = res.dimuon_mass#.compute()\n",
    "    \n",
    "    if(key=='dy'):\n",
    "        plt.hist(mass, bins=150, range=[0, 500], histtype=\"step\",linewidth=2, color='blue', label='DY+Jets')\n",
    "    elif(key == 'tt'):\n",
    "        plt.hist(mass, bins=150, range=[0,500], histtype='step',linewidth=2, color='orange', label='ttbar')\n",
    "    else:\n",
    "        n, bins, patches = plt.hist(mass, bins=150, range=[0,500], histtype='step',linewidth=0)\n",
    "\n",
    "        \n",
    "errory = np.sqrt(n)\n",
    "plt.errorbar(np.linspace(0,500,150), n,yerr= errory, fmt='o', markersize=3, color='k', label='Data')\n",
    "        \n",
    "    \n",
    "    \n",
    "plt.title('Dimuon invariant mass')\n",
    "plt.xlabel('Dimuon invariant mass [GeV]')\n",
    "plt.ylabel('Events')\n",
    "#plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(f\"dimuon_mass_parallel.pdf\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features = ['mu1_pt', 'mu1_eta', 'mu2_pt', 'mu2_eta', 'dimuon_mass','MET']\n",
    "\n",
    "df_sig = results['dy'][load_features]\n",
    "df_bkg = results['tt'][load_features]\n",
    "\n",
    "df_sig[\"label\"] = 1.0\n",
    "df_bkg[\"label\"] = 0.0\n",
    "\n",
    "dataset = dd.concat([df_sig, df_bkg], ignore_index=True)\n",
    "\n",
    "train_data, val_data = dataset.random_split([0.7, 0.3], shuffle=True)\n",
    "\n",
    "\n",
    "train_labels = train_data[\"label\"].compute().values\n",
    "val_labels = val_data[\"label\"].compute().values\n",
    "\n",
    "train = train_data.drop(columns=[\"label\"]).compute()\n",
    "train = train.dropna().values\n",
    "\n",
    "val = val_data.drop(columns=[\"label\"]).compute()\n",
    "val = val.dropna().values\n",
    "\n",
    "train_size = len(train_data)\n",
    "#dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lets train a network and apply some selections'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            layers.append(nn.ELU())\n",
    "            #layers.append(nn.Dropout(p=0.1))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weight    \n",
    "    def forward(self, x):\n",
    "        out = self.layers[0](x)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            out = self.layers[i](out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "input_size = len(load_features)\n",
    "hidden_sizes = [16, 8]\n",
    "learning_rate = 0.001\n",
    "num_classes = 1\n",
    "num_epochs =  20\n",
    "batch_size =  512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_sizes, num_classes).to(device)\n",
    "model = model.float()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "decayRate = 0.6\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "\n",
    "\n",
    "total_step = train_size\n",
    "\n",
    "print(\"RUNNING... \")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mean_loss = 0\n",
    "    tot_wgt = 0\n",
    "    val_mean_loss = 0\n",
    "    val_tot_wgt = 0\n",
    "    for i in range(int(train_size/batch_size)):\n",
    "        # Move tensors to the configured device\n",
    "        data = torch.from_numpy(train[i*batch_size: (i+1)*batch_size]).to(device)\n",
    "        label = torch.from_numpy(train_labels[i*batch_size: (i+1)*batch_size].reshape((batch_size,1))).to(device)\n",
    "\n",
    "        outputs = model(data.float())\n",
    "    \n",
    "        loss = criterion(outputs, label.float())\n",
    "        weight_loss = loss\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        weight_loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        mean_loss += weight_loss.mean().item()*batch_size\n",
    "\n",
    "        if i%4 == 0:\n",
    "            j = int(i/4)\n",
    "            val_data = torch.from_numpy(val[j*batch_size: (j+1)*batch_size]).to(device)\n",
    "            val_label = torch.from_numpy(val_labels[j*batch_size: (j+1)*batch_size].reshape(val_labels[j*batch_size: (j+1)*batch_size].shape[0],1)).to(device)\n",
    "            val_outputs = model(val_data.float())\n",
    "\n",
    "\n",
    "            val_loss = criterion(val_outputs, val_label.float())\n",
    "\n",
    "        if (i+1) % 150 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, int(total_step/batch_size), mean_loss, val_loss))\n",
    "            mean_loss=0\n",
    "            tot_wgt=0\n",
    "            val_mean_loss=0\n",
    "            val_tot_wgt=0\n",
    "    my_lr_scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "'''The model has been saved. Lets now evaluate the results'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the model'''\n",
    "\n",
    "df_sig = results['dy'][load_features]\n",
    "df_bkg = results['tt'][load_features]\n",
    "df_data = results['data'][load_features]\n",
    "\n",
    "def inference(df):\n",
    "    device = torch.device('cpu')\n",
    "    model = NeuralNet(6, [16, 8], 1).to(device)\n",
    "    model.load_state_dict(torch.load(\"model.ckpt\", map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    df = torch.from_numpy(df.compute().values).to(device).float()\n",
    "    scores = model(df) \n",
    "    scores = scores.cpu().detach().numpy()\n",
    "    return scores.ravel()    \n",
    "\n",
    "\n",
    "futures = client.map(inference, [df_sig, df_bkg, df_data])\n",
    "dnn_sig, dnn_bkg, dnn_data = client.gather(futures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "\n",
    "plt.hist(dnn_sig, bins, alpha=0.3, label='sig')\n",
    "plt.hist(dnn_bkg, bins, alpha=0.3, label='bkg')\n",
    "plt.xlabel('DNN Score')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_CUT = 0.6\n",
    "\n",
    "dy_mass_dnn = df_sig[\"dimuon_mass\"].compute()[dnn_sig>DNN_CUT]\n",
    "tt_mass_dnn = df_bkg[\"dimuon_mass\"].compute()[dnn_bkg>DNN_CUT]\n",
    "data_mass_dnn = df_data[\"dimuon_mass\"].compute()[dnn_data>DNN_CUT]\n",
    "\n",
    "\n",
    "'''Plot dimuon invariant mass'''\n",
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "plt.hist(dy_mass_dnn, bins=150, range=[0,500], histtype='step',linewidth=2, color='blue', label='DY+Jets')\n",
    "plt.hist(tt_mass_dnn, bins=150, range=[0,500], histtype='step',linewidth=2, color='orange', label='ttbar')\n",
    "n, bins, patches = plt.hist(data_mass_dnn, bins=150, range=[0,500], histtype='step',linewidth=0)\n",
    "\n",
    "errory = np.sqrt(n)\n",
    "plt.errorbar(np.linspace(0,500,150), n,yerr= errory, fmt='o', markersize=3, color='k', label='Data')\n",
    "\n",
    "plt.title('Dimuon invariant mass')\n",
    "plt.xlabel('Dimuon invariant mass [GeV]')\n",
    "plt.ylabel('Events')\n",
    "#plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig(f\"dimuon_mass_dnncut_parallel.pdf\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coffea_DASK_pyROOT_ML [spiperov]",
   "language": "python",
   "name": "coffea_dask_pyroot_ml_spiperov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
